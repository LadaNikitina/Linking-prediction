{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726baddc",
   "metadata": {},
   "source": [
    "# Dialogue Graph Auto Construction based on data with a regular structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af22fcd1",
   "metadata": {},
   "source": [
    "Goal: Extract regular structures from the data by building a dialogue graph\n",
    "    \n",
    "Tasks: \n",
    "* Cluster dialog data using embeddings of pre-trained models (BERT, ConveRT, S-BERT…)\n",
    "* Evaluate the quality of clustering using intent’s labeling of Multi-WoZ dataset \n",
    "* Linking clusters of dialogs using naive approaches (Estimation of Probabilities by Frequency Models)\n",
    "* Try other approaches (Deep Neural Networks) for linking clusters and improve the naive approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72eb4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 22:55:13.444462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-23 22:55:14.658916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-23 22:55:14.659055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-23 22:55:14.659067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import dgl\n",
    "import torch.nn.functional as F\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.insert(1, '/cephfs/home/ledneva/final_work/common_utils/')\n",
    "from preprocess import Clusters, get_accuracy_k, get_all_accuracy_k, get_all_accuracy_printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ead781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f64c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mladanik\u001b[0m (\u001b[33mladanik13\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cephfs/home/ledneva/final_work/MP_best/wandb/run-20230223_225518-7bw6ceio</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ladanik13/MP-tuning/runs/7bw6ceio\" target=\"_blank\">swift-grass-27</a></strong> to <a href=\"https://wandb.ai/ladanik13/MP-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/ladanik13/MP-tuning\" target=\"_blank\">https://wandb.ai/ladanik13/MP-tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/ladanik13/MP-tuning/runs/7bw6ceio\" target=\"_blank\">https://wandb.ai/ladanik13/MP-tuning/runs/7bw6ceio</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ladanik13/MP-tuning/runs/7bw6ceio?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f17a5451a00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"MP-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5f478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_function_uttr_embs import get_data\n",
    "from GAT_functions_uttr_embs import get_data_dgl_no_cycles\n",
    "from early_stopping_tools import LRScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bdc5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_num_clusters = 400\n",
    "second_num_clusters = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33449ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: multi_woz_v22/v2.2_active_only\n",
      "Found cached dataset multi_woz_v22 (/home/ledneva/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/6719c8b21478299411a0c6fdb7137c3ebab2e6425129af831687fb7851c69eb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb62473de2645c1955a7bd4a0939bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embeddings are loading...\n",
      "The first stage of clustering has begun...\n",
      "The second stage of clustering has begun...\n",
      "The searching clusters for test and validation has begun...\n",
      "Intent metric conveRT-one-prev, 60 two-stage clusters,                 user: 0.7291723035160729\n",
      "Intent metric conveRT-one-prev, 60 two-stage clusters,                 system: 0.7407125368469983\n"
     ]
    }
   ],
   "source": [
    "embs_path = \"/cephfs/home/ledneva/final_work/convert_one_prev_embeddings.csv\"\n",
    "clusters = Clusters(first_num_clusters, second_num_clusters, embs_path)\n",
    "clusters.form_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32905eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting unique intents\n",
    "unique_intent = []\n",
    "\n",
    "for intents in clusters.user_train_df['intent']:\n",
    "    unique_intent += intents\n",
    "for intents in clusters.system_train_df['intent']:\n",
    "    unique_intent += intents\n",
    "\n",
    "unique_intent = list(set(unique_intent))  \n",
    "num_intents = len(unique_intent)\n",
    "all_intents = []\n",
    "\n",
    "for i in range(second_num_clusters):\n",
    "    cluster = clusters.train_user_df[clusters.train_user_df['cluster'] == i]\n",
    "\n",
    "    intents = []\n",
    "    for intent_arr in cluster['intent']:\n",
    "        intents += intent_arr\n",
    "\n",
    "    intent_count = np.zeros(num_intents)\n",
    "    for j, intent in enumerate(unique_intent):\n",
    "        intent_count[j] = intents.count(intent)\n",
    "    all_intents.append(np.array(intent_count) / sum(intent_count))\n",
    "\n",
    "for i in range(second_num_clusters):\n",
    "    cluster = clusters.train_system_df[clusters.train_system_df['cluster'] == i]\n",
    "\n",
    "    intents = []\n",
    "    for intent_arr in cluster['intent']:\n",
    "        intents += intent_arr\n",
    "\n",
    "    intent_count = np.zeros(num_intents)\n",
    "    for j, intent in enumerate(unique_intent):\n",
    "        intent_count[j] = intents.count(intent)\n",
    "    all_intents.append(np.array(intent_count) / sum(intent_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca206193",
   "metadata": {},
   "source": [
    "## 4.3 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe0e1d",
   "metadata": {},
   "source": [
    "Functions generating butches for two types of graphs and metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7a2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb87383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 15\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc95d7",
   "metadata": {},
   "source": [
    "## 4.4 Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8091c",
   "metadata": {},
   "source": [
    "Data generation and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70a61a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_x, user_train_y, sys_train_x, sys_train_y = get_data(clusters.train_dataset, \n",
    "                                                                top_k, second_num_clusters, \n",
    "                                                                clusters.train_user_df, \n",
    "                                                                clusters.train_system_df,\n",
    "                                                                np.array(clusters.train_user_embs),\n",
    "                                                                np.array(clusters.train_system_embs))\n",
    "user_test_x, user_test_y, sys_test_x, sys_test_y = get_data(clusters.test_dataset, \n",
    "                                                            top_k, second_num_clusters,\n",
    "                                                            clusters.test_user_df,\n",
    "                                                            clusters.test_system_df,\n",
    "                                                            np.array(clusters.test_user_embs),\n",
    "                                                            np.array(clusters.test_system_embs))\n",
    "user_valid_x, user_valid_y, sys_valid_x, sys_valid_y = get_data(clusters.validation_dataset, \n",
    "                                                                top_k, second_num_clusters,\n",
    "                                                                clusters.valid_user_df, \n",
    "                                                                clusters.valid_system_df,\n",
    "                                                                np.array(clusters.valid_user_embs),\n",
    "                                                                np.array(clusters.valid_system_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09306168",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_data = get_data_dgl_no_cycles(user_train_x, user_train_y, 1, top_k, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac5ee3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_train_data = get_data_dgl_no_cycles(sys_train_x, sys_train_y, 1, top_k, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90a3099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test_data = get_data_dgl_no_cycles(user_test_x, user_test_y, 0, top_k, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d95c0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_test_data = get_data_dgl_no_cycles(sys_test_x, sys_test_y, 0, top_k, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af0e6ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_valid_data = get_data_dgl_no_cycles(user_valid_x, user_valid_y, 1, top_k, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b303b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_valid_data = get_data_dgl_no_cycles(sys_valid_x, sys_valid_y, 1, top_k, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e65e063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучаемые веса для суммирования\n",
    "linear_weights = np.zeros(top_k)\n",
    "linear_weights[...] = 1 / top_k\n",
    "linear_weights = torch.tensor(linear_weights).view(1, -1)\n",
    "linear_weights = linear_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e5adef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_embs_dim = len(all_intents[0])\n",
    "centre_embs_dim = len(clusters.user_cluster_embs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeb34616",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comps = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9cbd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_embs_dim = num_comps\n",
    "learn_emb = nn.Parameter(\n",
    "            torch.Tensor(2 * second_num_clusters + 1, learn_embs_dim), requires_grad=False\n",
    ")\n",
    "learn_emb = torch.Tensor(nn.init.xavier_uniform_(learn_emb))\n",
    "# обучаемый эмбеддинг\n",
    "# weights = torch.Tensor(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca9b2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cluster_centre_emb = np.zeros(centre_embs_dim)\n",
    "null_cluster_intent_emb = np.zeros(intent_embs_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a28f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "centre_mass = torch.Tensor(np.concatenate([clusters.user_cluster_embs, \n",
    "                                           clusters.system_cluster_embs, \n",
    "                                           [null_cluster_centre_emb]])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae2b7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_embs = torch.Tensor(np.concatenate([all_intents, [null_cluster_intent_emb]])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24348632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_cluster_intents, system_cluster_intents - intents\n",
    "# clusters.user_cluster_embs, clusters.system_cluster_embs - center of mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0ad83",
   "metadata": {},
   "source": [
    "## 4.5 Prediction of user clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06d56a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 2048\n",
    "# embs_dim = 512 + len(centre_mass[0]) + learn_embs_dim + len(intent_embs[0])\n",
    "embs_dim = 512\n",
    "num_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c4d177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl import nn as dgl_nn\n",
    "from torch import nn\n",
    "\n",
    "class GAT_user(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads):\n",
    "        super(GAT_user, self).__init__()\n",
    "\n",
    "        self.embs = nn.Embedding.from_pretrained(learn_emb).requires_grad_(True)\n",
    "        self.layer1 = dgl_nn.GATv2Conv(embs_dim, hidden_dim, num_heads)\n",
    "        self.layer2 = dgl_nn.GATv2Conv(hidden_dim * num_heads, hidden_dim, num_heads)\n",
    "\n",
    "        self.do1 = nn.Dropout(0.4)\n",
    "        self.do2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.linear_weights = nn.Embedding.from_pretrained(linear_weights.float()).requires_grad_(True)  \n",
    "        \n",
    "        self.classify = nn.Linear(hidden_dim * num_heads, second_num_clusters)\n",
    "\n",
    "    def forward(self, bg):\n",
    "        x = bg.ndata['attr']\n",
    "        x_emb = bg.ndata['emb']\n",
    "        embeddings = self.embs.weight\n",
    "        all_embs = torch.concat((embeddings, centre_mass, intent_embs), dim = 1)\n",
    "        \n",
    "        get_embs = lambda i: all_embs[i]\n",
    "        node_embs = get_embs(x)\n",
    "        \n",
    "#         result_embs = torch.concat((node_embs, x_emb), dim = 1)\n",
    "        result_embs = x_emb\n",
    "        h = result_embs.to(torch.float32)\n",
    "        \n",
    "        h = self.layer1(bg, h)\n",
    "        h = self.do1(h)\n",
    "        h = torch.reshape(h, (len(h), num_heads * hidden_dim))      \n",
    "        h = self.layer2(bg, h)\n",
    "        h = self.do2(h)\n",
    "\n",
    "        \n",
    "        bg.ndata['h'] = h\n",
    "        h = torch.reshape(h, (len(node_embs) // top_k, top_k, num_heads * hidden_dim))        \n",
    "        linear_weights_1dim = torch.reshape(self.linear_weights.weight, (top_k, ))\n",
    "        get_sum = lambda e: torch.matmul(linear_weights_1dim, e)\n",
    "        h = list(map(get_sum, h))\n",
    "        hg = torch.stack(h)\n",
    "        return self.classify(hg)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d261932a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 3.4972, valid loss 3.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss 2.8418, valid loss 2.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss 2.4429, valid loss 2.3288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss 2.1993, valid loss 2.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss 2.0834, valid loss 2.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss 2.0142, valid loss 2.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss 1.9679, valid loss 1.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss 1.9351, valid loss 1.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss 1.9084, valid loss 1.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss 1.8900, valid loss 1.9483\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss 1.8735, valid loss 1.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:43,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train loss 1.8621, valid loss 1.9392\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, train loss 1.8493, valid loss 1.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, train loss 1.8403, valid loss 1.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train loss 1.8303, valid loss 1.9145\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, train loss 1.8208, valid loss 1.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train loss 1.8124, valid loss 1.9067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, train loss 1.8038, valid loss 1.9195\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [01:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, train loss 1.7962, valid loss 1.9077\n",
      "Early stopping counter 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [01:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, train loss 1.7891, valid loss 1.9066\n",
      "Epoch 00020: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Early stopping counter 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [01:01,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, train loss 1.7737, valid loss 1.9074\n",
      "Early stopping counter 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [01:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, train loss 1.7679, valid loss 1.9120\n",
      "Early stopping counter 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:57,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, train loss 1.7626, valid loss 1.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:52,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, train loss 1.7612, valid loss 1.9082\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, train loss 1.7564, valid loss 1.9082\n",
      "Early stopping counter 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, train loss 1.7513, valid loss 1.9079\n",
      "Epoch 00026: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Early stopping counter 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, train loss 1.7429, valid loss 1.9091\n",
      "Early stopping counter 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, train loss 1.7407, valid loss 1.9048\n",
      "Early stopping counter 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, train loss 1.7385, valid loss 1.9111\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Early stopping counter 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, train loss 1.7339, valid loss 1.9078\n",
      "Early stopping counter 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, train loss 1.7321, valid loss 1.9099\n",
      "Early stopping counter 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, train loss 1.7328, valid loss 1.9043\n",
      "Epoch 00032: reducing learning rate of group 0 to 6.2500e-06.\n",
      "Early stopping counter 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, train loss 1.7295, valid loss 1.9114\n",
      "Early stopping counter 10 of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "user_model = GAT_user(hidden_dim, num_heads).to(device)\n",
    "user_train_epoch_losses = []\n",
    "user_valid_epoch_losses = []\n",
    "\n",
    "for param in user_model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(user_model.parameters(), lr = 0.0001)\n",
    "lr_scheduler = LRScheduler(optimizer)\n",
    "early_stopping = EarlyStopping(10)\n",
    "\n",
    "user_num_epochs = 100\n",
    "\n",
    "for epoch in range(user_num_epochs):\n",
    "    train_epoch_loss = 0\n",
    "\n",
    "    for iter, (batched_graph, labels) in tqdm(enumerate(user_train_data)):\n",
    "#         print(f\"{iter} / {len(user_train_data)}\")\n",
    "        out = user_model(batched_graph.to(device))\n",
    "        loss = criterion(out, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        train_epoch_loss += loss.detach().item()\n",
    "        \n",
    "    train_epoch_loss /= (iter + 1)\n",
    "    user_train_epoch_losses.append(train_epoch_loss)\n",
    "    \n",
    "    valid_epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for iter, (batched_graph, labels) in enumerate(user_valid_data):\n",
    "            out = user_model(batched_graph.to(device))\n",
    "            loss = criterion(out, labels.to(device))\n",
    "            valid_epoch_loss += loss.detach().item()\n",
    "\n",
    "        valid_epoch_loss /= (iter + 1)\n",
    "        user_valid_epoch_losses.append(valid_epoch_loss)\n",
    "    print(f'Epoch {epoch}, train loss {train_epoch_loss:.4f}, valid loss {valid_epoch_loss:.4f}')  \n",
    "    wandb.log({'Epoch' : epoch, 'user train loss' : train_epoch_loss, 'user valid loss' : valid_epoch_loss})\n",
    "    \n",
    "    lr_scheduler(valid_epoch_loss)\n",
    "    early_stopping(valid_epoch_loss)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73876cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f16568ee4c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('user model cross entropy averaged over minibatches')\n",
    "plt.plot(user_train_epoch_losses, label = \"train\")\n",
    "plt.plot(user_valid_epoch_losses, label = \"valid\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34115eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model.eval()\n",
    "user_test_X, user_test_Y = map(list, zip(*user_test_data))\n",
    "\n",
    "user_probs = []\n",
    "user_test = []\n",
    "\n",
    "for i in range(len(user_test_Y)):\n",
    "    g = user_test_X[i].to(device)\n",
    "    labels = user_test_Y[i]\n",
    "    labels = labels.tolist()\n",
    "    user_test += labels\n",
    "    user_probs_Y = torch.softmax(user_model(g), 1).tolist()\n",
    "    user_probs += user_probs_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c56ee706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER metric\n",
      "Acc@1: 0.43422832445332443\n",
      "Acc@3: 0.7114723776223777\n",
      "Acc@5: 0.8181893162393162\n",
      "Acc@10: 0.9238690281940283\n"
     ]
    }
   ],
   "source": [
    "print(\"USER metric\")\n",
    "\n",
    "print(\"Acc@1:\", get_accuracy_k(1, clusters.test_user_df, user_probs, clusters.test_dataset, 0))\n",
    "print(\"Acc@3:\", get_accuracy_k(3, clusters.test_user_df, user_probs, clusters.test_dataset, 0))\n",
    "print(\"Acc@5:\", get_accuracy_k(5, clusters.test_user_df, user_probs, clusters.test_dataset, 0))\n",
    "print(\"Acc@10:\", get_accuracy_k(10, clusters.test_user_df, user_probs, clusters.test_dataset, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ced9e",
   "metadata": {},
   "source": [
    "## 4.6 Prediction of system clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb21ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl import nn as dgl_nn\n",
    "from torch import nn\n",
    "\n",
    "class GAT_system(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads):\n",
    "        super(GAT_system, self).__init__()\n",
    "\n",
    "        self.embs = nn.Embedding.from_pretrained(learn_emb).requires_grad_(True)\n",
    "        self.layer1 = dgl_nn.GATv2Conv(embs_dim, hidden_dim, num_heads)\n",
    "        self.layer2 = dgl_nn.GATv2Conv(hidden_dim * num_heads, hidden_dim, num_heads)\n",
    "\n",
    "        self.do1 = nn.Dropout(0.4)\n",
    "        self.do2 = nn.Dropout(0.4)\n",
    "\n",
    "        self.linear_weights = nn.Embedding.from_pretrained(linear_weights.float()).requires_grad_(True)  \n",
    "        \n",
    "        self.classify = nn.Linear(hidden_dim * num_heads, second_num_clusters)\n",
    "\n",
    "    def forward(self, bg):\n",
    "        x = bg.ndata['attr']\n",
    "        x_emb = bg.ndata['emb']\n",
    "        embeddings = self.embs.weight\n",
    "        all_embs = torch.concat((embeddings, centre_mass, intent_embs), dim = 1)\n",
    "        \n",
    "        get_embs = lambda i: all_embs[i]\n",
    "        node_embs = get_embs(x)\n",
    "        \n",
    "#         result_embs = torch.concat((node_embs, x_emb), dim = 1)\n",
    "        result_embs = x_emb\n",
    "        h = result_embs.to(torch.float32)\n",
    "        \n",
    "        h = self.layer1(bg, h)\n",
    "        h = self.do1(h)\n",
    "        h = torch.reshape(h, (len(h), num_heads * hidden_dim))      \n",
    "        h = self.layer2(bg, h)\n",
    "        h = self.do2(h)\n",
    "\n",
    "        \n",
    "        bg.ndata['h'] = h\n",
    "        h = torch.reshape(h, (len(node_embs) // top_k, top_k, num_heads * hidden_dim))        \n",
    "        linear_weights_1dim = torch.reshape(self.linear_weights.weight, (top_k, ))\n",
    "        get_sum = lambda e: torch.matmul(linear_weights_1dim, e)\n",
    "        h = list(map(get_sum, h))\n",
    "        hg = torch.stack(h)\n",
    "        return self.classify(hg)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "104c1fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:47,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss 3.5192, valid loss 3.2904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss 2.7656, valid loss 2.6304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train loss 2.2025, valid loss 2.1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train loss 1.8834, valid loss 1.9223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train loss 1.7068, valid loss 1.7964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train loss 1.6121, valid loss 1.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train loss 1.5539, valid loss 1.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train loss 1.5148, valid loss 1.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train loss 1.4845, valid loss 1.6106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train loss 1.4602, valid loss 1.5991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss 1.4394, valid loss 1.6089\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train loss 1.4229, valid loss 1.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, train loss 1.4086, valid loss 1.5748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:46,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, train loss 1.3942, valid loss 1.5755\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train loss 1.3854, valid loss 1.5745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, train loss 1.3730, valid loss 1.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train loss 1.3613, valid loss 1.5629\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, train loss 1.3526, valid loss 1.5760\n",
      "Early stopping counter 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, train loss 1.3437, valid loss 1.5674\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Early stopping counter 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:45,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, train loss 1.3257, valid loss 1.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, train loss 1.3209, valid loss 1.5612\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, train loss 1.3165, valid loss 1.5575\n",
      "Early stopping counter 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, train loss 1.3102, valid loss 1.5652\n",
      "Epoch 00023: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Early stopping counter 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, train loss 1.3016, valid loss 1.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, train loss 1.2992, valid loss 1.5644\n",
      "Early stopping counter 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, train loss 1.2962, valid loss 1.5564\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Early stopping counter 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:44,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, train loss 1.2924, valid loss 1.5604\n",
      "Early stopping counter 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:56,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, train loss 1.2895, valid loss 1.5623\n",
      "Early stopping counter 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:59,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, train loss 1.2900, valid loss 1.5555\n",
      "Epoch 00029: reducing learning rate of group 0 to 6.2500e-06.\n",
      "Early stopping counter 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:59,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, train loss 1.2859, valid loss 1.5564\n",
      "Early stopping counter 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:58,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, train loss 1.2864, valid loss 1.5594\n",
      "Early stopping counter 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:58,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, train loss 1.2853, valid loss 1.5549\n",
      "Epoch 00032: reducing learning rate of group 0 to 3.1250e-06.\n",
      "Early stopping counter 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [01:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, train loss 1.2849, valid loss 1.5617\n",
      "Early stopping counter 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [00:49,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, train loss 1.2847, valid loss 1.5588\n",
      "Early stopping counter 10 of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "system_model = GAT_system(hidden_dim, num_heads).to(device)\n",
    "\n",
    "for param in system_model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(system_model.parameters(), lr = 0.0001)\n",
    "lr_scheduler = LRScheduler(optimizer)\n",
    "early_stopping = EarlyStopping(10)\n",
    "\n",
    "sys_num_epochs = 100\n",
    "\n",
    "for epoch in range(sys_num_epochs):\n",
    "    train_epoch_loss = 0\n",
    "\n",
    "    for iter, (batched_graph, labels) in tqdm(enumerate(sys_train_data)):\n",
    "#         print(f\"{iter}/{len(sys_train_data)}\")\n",
    "        out = system_model(batched_graph.to(device))\n",
    "        loss = criterion(out, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        train_epoch_loss += loss.detach().item()\n",
    "        \n",
    "    train_epoch_loss /= (iter + 1)\n",
    "    \n",
    "    valid_epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for iter, (batched_graph, labels) in enumerate(sys_valid_data):\n",
    "            out = system_model(batched_graph.to(device))\n",
    "            loss = criterion(out, labels.to(device))\n",
    "            \n",
    "            valid_epoch_loss += loss.detach().item()\n",
    "\n",
    "        valid_epoch_loss /= (iter + 1)\n",
    "\n",
    "    print(f'Epoch {epoch}, train loss {train_epoch_loss:.4f}, valid loss {valid_epoch_loss:.4f}')  \n",
    "    wandb.log({'system train loss' : train_epoch_loss, 'system valid loss' : valid_epoch_loss})\n",
    "    lr_scheduler(valid_epoch_loss)\n",
    "    early_stopping(valid_epoch_loss)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02078fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_model.eval()\n",
    "system_test_X, system_test_Y = map(list, zip(*sys_test_data))\n",
    "\n",
    "system_probs = []\n",
    "system_test = []\n",
    "\n",
    "for i in range(len(system_test_Y)):\n",
    "    g = system_test_X[i].to(device)\n",
    "    labels = system_test_Y[i]\n",
    "    labels = labels.tolist()\n",
    "    system_test += labels\n",
    "    system_probs_Y = torch.softmax(system_model(g), 1).tolist()\n",
    "    system_probs += system_probs_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f8fae1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM metric\n",
      "Acc@1: 0.5099656066156066\n",
      "Acc@3: 0.8220969363969364\n",
      "Acc@5: 0.9135968697968699\n",
      "Acc@10: 0.9688914196914198\n"
     ]
    }
   ],
   "source": [
    "print(\"SYSTEM metric\")\n",
    "\n",
    "print(\"Acc@1:\", get_accuracy_k(1, clusters.test_system_df, system_probs, clusters.test_dataset, 1))\n",
    "print(\"Acc@3:\", get_accuracy_k(3, clusters.test_system_df, system_probs, clusters.test_dataset, 1))\n",
    "print(\"Acc@5:\", get_accuracy_k(5, clusters.test_system_df, system_probs, clusters.test_dataset, 1))\n",
    "print(\"Acc@10:\", get_accuracy_k(10, clusters.test_system_df, system_probs, clusters.test_dataset, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f710fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL metric\n",
      "Acc@1: 0.47209696553446556\n",
      "Acc@3: 0.7667846570096569\n",
      "Acc@5: 0.865893093018093\n",
      "Acc@10: 0.9463802239427239\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL metric\")\n",
    "print(\"Acc@1:\", get_all_accuracy_k(1, clusters.test_user_df, clusters.test_system_df, user_probs, system_probs, clusters.test_dataset))\n",
    "print(\"Acc@3:\", get_all_accuracy_k(3, clusters.test_user_df, clusters.test_system_df, user_probs, system_probs, clusters.test_dataset))\n",
    "print(\"Acc@5:\", get_all_accuracy_k(5, clusters.test_user_df, clusters.test_system_df, user_probs, system_probs, clusters.test_dataset))\n",
    "print(\"Acc@10:\", get_all_accuracy_k(10, clusters.test_user_df, clusters.test_system_df, user_probs, system_probs, clusters.test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599042c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd805778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
