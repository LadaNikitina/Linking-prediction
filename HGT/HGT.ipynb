{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726baddc",
   "metadata": {},
   "source": [
    "# Dialogue Graph Auto Construction based on data with a regular structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af22fcd1",
   "metadata": {},
   "source": [
    "Goal: Extract regular structures from the data by building a dialogue graph\n",
    "    \n",
    "Tasks: \n",
    "* Cluster dialog data using embeddings of pre-trained models (BERT, ConveRT, S-BERT…)\n",
    "* Evaluate the quality of clustering using intent’s labeling of Multi-WoZ dataset \n",
    "* Linking clusters of dialogs using naive approaches (Estimation of Probabilities by Frequency Models)\n",
    "* Try other approaches (Deep Neural Networks) for linking clusters and improve the naive approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe983625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import dgl\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d80e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce713e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/cephfs/home/ledneva/final_work/common_utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3546905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_function import get_data\n",
    "from HGT_functions import get_data_dgl\n",
    "from HGT_model import HGT\n",
    "from early_stopping_tools import LRScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2652325",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_num_clusters = 400\n",
    "second_num_clusters = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Clusters, get_accuracy_k, get_all_accuracy_k\n",
    "path = \"/cephfs/home/ledneva/final_work/convert_one_prev_embeddings.csv\"\n",
    "clusters = Clusters(first_num_clusters, second_num_clusters, path)\n",
    "clusters.form_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242efc4b",
   "metadata": {},
   "source": [
    "## 4.1 HGT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe0e1d",
   "metadata": {},
   "source": [
    "Functions generating butches for two types of graphs and metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39289fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_dim = len(clusters.user_cluster_embs[0])\n",
    "top_k = 10\n",
    "batch_size = 256\n",
    "null_cluster = 2 * second_num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cluster_emb = np.zeros(embs_dim)\n",
    "\n",
    "embs = np.concatenate([clusters.user_cluster_embs, clusters.system_cluster_embs, [null_cluster_emb, null_cluster_emb]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc95d7",
   "metadata": {},
   "source": [
    "## 4.4 Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8091c",
   "metadata": {},
   "source": [
    "Data generation and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a61a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_x, user_train_y, user_train_embs, \\\n",
    "sys_train_x, sys_train_y, sys_train_embs = get_data(clusters.train_dataset, top_k, \n",
    "                                                    second_num_clusters, \n",
    "                                                    clusters.train_user_df, \n",
    "                                                    clusters.train_system_df,\n",
    "                                                    clusters.train_user_embs,\n",
    "                                                    clusters.train_system_embs)\n",
    "user_test_x, user_test_y, user_test_embs, \\\n",
    "sys_test_x, sys_test_y, sys_test_embs = get_data(clusters.test_dataset, top_k,\n",
    "                                                 second_num_clusters, \n",
    "                                                 clusters.test_user_df, \n",
    "                                                 clusters.test_system_df,\n",
    "                                                 clusters.test_user_embs,\n",
    "                                                 clusters.test_system_embs)\n",
    "user_valid_x, user_valid_y, user_valid_embs, \\\n",
    "sys_valid_x, sys_valid_y, sys_valid_embs = get_data(clusters.validation_dataset, \n",
    "                                                    top_k, second_num_clusters, \n",
    "                                                    clusters.valid_user_df, \n",
    "                                                    clusters.valid_system_df,\n",
    "                                                    clusters.valid_user_embs,\n",
    "                                                    clusters.valid_system_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa60d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = {}\n",
    "edge_dict = {}\n",
    "for ntype in range(null_cluster + 2):\n",
    "    node_dict[str(ntype)] = len(node_dict)\n",
    "\n",
    "edge_dict['user'] = 0\n",
    "edge_dict['system'] = 1\n",
    "edge_dict['null'] = 2\n",
    "edge_dict['self'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa85783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_train = get_data_dgl(user_train_x, user_train_y,\n",
    "                          batch_size, top_k, embs,\n",
    "                          np.array(user_train_embs), \n",
    "                          second_num_clusters, 1)\n",
    "sys_train =  get_data_dgl(sys_train_x, sys_train_y, \n",
    "                         batch_size, top_k, embs,\n",
    "                         np.array(sys_train_embs), \n",
    "                         second_num_clusters, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deddb98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_test = get_data_dgl(user_test_x, user_test_y,\n",
    "                         batch_size, top_k, embs, \n",
    "                         np.array(user_test_embs),\n",
    "                         second_num_clusters, 0)\n",
    "sys_test = get_data_dgl(sys_test_x, sys_test_y,\n",
    "                        batch_size, top_k, embs, \n",
    "                        np.array(sys_test_embs), \n",
    "                        second_num_clusters, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ea8f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_valid = get_data_dgl(user_valid_x, user_valid_y, \n",
    "                          batch_size, top_k, embs, \n",
    "                          np.array(user_valid_embs),\n",
    "                          second_num_clusters, 1)\n",
    "sys_valid = get_data_dgl(sys_valid_x, sys_valid_y,\n",
    "                         batch_size, top_k, embs, \n",
    "                         np.array(sys_valid_embs),\n",
    "                         second_num_clusters, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774407e",
   "metadata": {},
   "source": [
    "## User_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205209d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class user_HGT_arguments:\n",
    "    epoch = 20 # эпохи!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f425b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_args = user_HGT_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = HGT(node_dict = node_dict,\n",
    "                     edge_dict = edge_dict,\n",
    "                     n_inp = 256,\n",
    "                     n_hid = 512,\n",
    "                     n_out = second_num_clusters + 1,\n",
    "                     n_layers = 3,\n",
    "                     n_heads = 1,\n",
    "                     top_k = top_k, \n",
    "                     use_norm=True)\n",
    "\n",
    "user_optimizer = torch.optim.Adam(user_model.parameters(), lr=0.001)\n",
    "user_lr_scheduler = LRScheduler(user_optimizer, min_lr = 0.000001)\n",
    "# user_early_stopping = EarlyStopping(1, 0.5)\n",
    "\n",
    "user_model.to(device)\n",
    "user_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be940b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_num_batches = len(user_train)\n",
    "valid_num_batches = len(user_valid)\n",
    "train_step = 1500\n",
    "node_features = torch.from_numpy(embs).float().to(device)\n",
    "pred_valid_loss = None\n",
    "\n",
    "for epoch in range(user_args.epoch):\n",
    "    start_time = time.time()\n",
    "    train_epoch_loss = 0\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for num_iter in tqdm(range(train_num_batches)):\n",
    "        g = user_train[num_iter][0].to(device)\n",
    "        graphs = torch.tensor(user_train[num_iter][1]).to(device)\n",
    "        y_true = torch.from_numpy(user_train[num_iter][2]).to(device)\n",
    "        etypes = user_train[num_iter][3]\n",
    "        vtypes = user_train[num_iter][4]\n",
    "        \n",
    "        user_model.zero_grad()\n",
    "        user_model.train()\n",
    "\n",
    "        y_train = user_model(g, graphs, etypes, vtypes)\n",
    "        if second_num_clusters in y_true:\n",
    "            train_loss = user_loss(y_train[y_true != second_num_clusters], \n",
    "                                   y_true[y_true != second_num_clusters])\n",
    "        else:\n",
    "            train_loss = user_loss(y_train, y_true)\n",
    "\n",
    "        user_optimizer.zero_grad() \n",
    "        torch.cuda.empty_cache()\n",
    "        train_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(user_model.parameters(), 0.25)\n",
    "        user_optimizer.step()\n",
    "        train_epoch_loss += train_loss.detach().item()\n",
    "        train_step += 1\n",
    "#         user_lr_scheduler.step(train_step)\n",
    "#         print(num_iter)\n",
    "        \n",
    "    train_epoch_loss /= train_num_batches\n",
    "\n",
    "    valid_epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for num_iter in tqdm(range(valid_num_batches)):\n",
    "            g = user_valid[num_iter][0].to(device)\n",
    "            graphs = torch.tensor(user_valid[num_iter][1]).to(device)\n",
    "            y_true = torch.from_numpy(user_valid[num_iter][2]).to(device)\n",
    "            etypes = user_valid[num_iter][3]\n",
    "            vtypes = user_valid[num_iter][4]\n",
    "            \n",
    "            y_valid = user_model.forward(g, graphs, etypes, vtypes)\n",
    "            \n",
    "            if second_num_clusters in y_true:\n",
    "                valid_loss = user_loss(y_valid[y_true != second_num_clusters], \n",
    "                                       y_true[y_true != second_num_clusters])\n",
    "            else:\n",
    "                valid_loss = user_loss(y_valid, y_true)\n",
    "\n",
    "            # тут считать лосс, выкинуть фейки\n",
    "            valid_epoch_loss += valid_loss.detach().item()\n",
    "        \n",
    "        valid_epoch_loss /= valid_num_batches\n",
    "    \n",
    "    print(f'Epoch {epoch}, train loss {train_epoch_loss:.4f}, \\\n",
    "           valid loss {valid_epoch_loss:.4f}, time {time.time() - start_time}')  \n",
    "    \n",
    "    if pred_valid_loss != None and valid_epoch_loss > pred_valid_loss:\n",
    "        break\n",
    "    \n",
    "    pred_valid_loss = valid_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model.eval()\n",
    "test_num_batches = len(user_test)\n",
    "user_true = []\n",
    "user_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for num_iter in tqdm(range(test_num_batches)):\n",
    "        g = user_test[num_iter][0].to(device)\n",
    "        graphs = torch.tensor(user_test[num_iter][1]).to(device)\n",
    "        y_true = torch.from_numpy(user_test[num_iter][2]).to(device)\n",
    "        etypes = user_test[num_iter][3]\n",
    "        vtypes = user_test[num_iter][4]\n",
    "        \n",
    "        probs = user_model.forward(g, graphs, etypes, vtypes)\n",
    "        y_pred = torch.softmax(probs, 1)\n",
    "        \n",
    "        if second_num_clusters in y_true:\n",
    "            user_pred += y_pred[y_true != second_num_clusters].tolist()\n",
    "            user_true += y_true[y_true != second_num_clusters].tolist()\n",
    "        else:\n",
    "            user_pred += y_pred.tolist()\n",
    "            user_true += y_true.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edb2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"USER metric\")\n",
    "\n",
    "print(\"Acc@1:\", get_accuracy_k(1, clusters.test_user_df, user_pred, clusters.test_dataset, 0))\n",
    "print(\"Acc@3:\", get_accuracy_k(3, clusters.test_user_df, user_pred, clusters.test_dataset, 0))\n",
    "print(\"Acc@5:\", get_accuracy_k(5, clusters.test_user_df, user_pred, clusters.test_dataset, 0))\n",
    "print(\"Acc@10:\", get_accuracy_k(10, clusters.test_user_df, user_pred, clusters.test_dataset, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30538fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380ffca",
   "metadata": {},
   "source": [
    "## System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sys_HGT_arguments:\n",
    "    epoch = 5 # эпохи!!!\n",
    "    lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf85b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_args = sys_HGT_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaea7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_model = HGT(node_dict = node_dict,\n",
    "                 edge_dict = edge_dict,\n",
    "                 n_inp = 612,\n",
    "                 n_hid = 16,\n",
    "                 n_out = second_num_clusters + 1,\n",
    "                 n_layers = 3,\n",
    "                 n_heads = 1,\n",
    "                 top_k = top_k, \n",
    "                 use_norm=True)\n",
    "\n",
    "sys_optimizer = torch.optim.Adam(sys_model.parameters(), lr=sys_args.lr)\n",
    "sys_lr_scheduler = LRScheduler(sys_optimizer, min_lr = 0.000001)\n",
    "sys_early_stopping = EarlyStopping(1, 0.1)\n",
    "\n",
    "sys_model.to(device)\n",
    "sys_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a449fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_num_batches = len(sys_train)\n",
    "valid_num_batches = len(sys_valid)\n",
    "node_features = torch.from_numpy(embs).float().to(device)\n",
    "\n",
    "for epoch in range(sys_args.epoch):\n",
    "    start_time = time.time()\n",
    "    train_epoch_loss = 0\n",
    "    \n",
    "    for num_iter in range(train_num_batches):\n",
    "        print(f\"Train: batch {num_iter}, epoch {epoch}\")\n",
    "        g = sys_train[num_iter][0].to(device)\n",
    "        graphs = torch.tensor(sys_train[num_iter][1]).to(device)\n",
    "        y_true = torch.from_numpy(sys_train[num_iter][2]).to(device)\n",
    "        etypes = sys_train[num_iter][3]\n",
    "        vtypes = sys_train[num_iter][4]\n",
    "        \n",
    "        sys_model.zero_grad()\n",
    "        sys_model.train()\n",
    "\n",
    "        y_train = sys_model(g, graphs, etypes, vtypes)\n",
    "        if second_num_clusters in y_true:\n",
    "            train_loss = sys_loss(y_train[y_true != second_num_clusters], y_true[y_true != second_num_clusters])\n",
    "        else:\n",
    "            train_loss = sys_loss(y_train, y_true)\n",
    "\n",
    "        train_loss.backward()\n",
    "        sys_optimizer.step()\n",
    "        train_epoch_loss += train_loss.detach().item()\n",
    "#         print(num_iter)\n",
    "        \n",
    "    train_epoch_loss /= train_num_batches\n",
    "\n",
    "    valid_epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for num_iter in range(valid_num_batches):\n",
    "            print(\"Valid\", num_iter, \"epoch\", epoch)\n",
    "            g = sys_valid[num_iter][0].to(device)\n",
    "            graphs = torch.tensor(sys_valid[num_iter][1]).to(device)\n",
    "\n",
    "            y_true = torch.from_numpy(sys_valid[num_iter][2]).to(device)\n",
    "            etypes = sys_valid[num_iter][3]\n",
    "            vtypes = sys_valid[num_iter][4]\n",
    "            \n",
    "            y_valid = sys_model.forward(g, graphs, etypes, vtypes)\n",
    "            \n",
    "            if second_num_clusters in y_true:\n",
    "                valid_loss = sys_loss(y_valid[y_true != second_num_clusters], y_true[y_true != second_num_clusters])\n",
    "            else:\n",
    "                valid_loss = sys_loss(y_valid, y_true)\n",
    "\n",
    "            # тут считать лосс, выкинуть фейки\n",
    "            valid_epoch_loss += valid_loss.detach().item()\n",
    "        \n",
    "        valid_epoch_loss /= valid_num_batches\n",
    "    \n",
    "    print(f'Epoch {epoch}, train loss {train_epoch_loss:.4f}, \\\n",
    "          valid loss {valid_epoch_loss:.4f}, \\\n",
    "          time {time.time() - start_time}')  \n",
    "    \n",
    "    sys_lr_scheduler(valid_epoch_loss)\n",
    "    sys_early_stopping(valid_epoch_loss)\n",
    "    \n",
    "    if sys_early_stopping.early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707acdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_model.eval()\n",
    "test_num_batches = len(sys_test)\n",
    "sys_true = []\n",
    "sys_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for num_iter in range(test_num_batches):\n",
    "        g = sys_test[num_iter][0].to(device)\n",
    "        graphs = torch.tensor(sys_test[num_iter][1]).to(device)\n",
    "        y_true = torch.from_numpy(sys_test[num_iter][2]).to(device)\n",
    "        etypes = sys_test[num_iter][3]\n",
    "        vtypes = sys_test[num_iter][4]\n",
    "        \n",
    "        probs = sys_model.forward(g, graphs, etypes, vtypes)\n",
    "        y_pred = torch.softmax(probs, 1)\n",
    "        \n",
    "        if second_num_clusters in y_true:\n",
    "            sys_pred += y_pred[y_true != second_num_clusters].tolist()\n",
    "            sys_true += y_true[y_true != second_num_clusters].tolist()\n",
    "        else:\n",
    "            sys_pred += y_pred.tolist()\n",
    "            sys_true += y_true.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SYSTEM metric\")\n",
    "\n",
    "print(\"Acc@1:\", get_accuracy_k(1, clusters.test_system_df, sys_pred, clusters.test_dataset, 1))\n",
    "print(\"Acc@3:\", get_accuracy_k(3, clusters.test_system_df, sys_pred, clusters.test_dataset, 1))\n",
    "print(\"Acc@5:\", get_accuracy_k(5, clusters.test_system_df, sys_pred, clusters.test_dataset, 1))\n",
    "print(\"Acc@10:\", get_accuracy_k(10, clusters.test_system_df, sys_pred, clusters.test_dataset, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb247735",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ALL metric\")\n",
    "print(\"Acc@1:\", get_all_accuracy_k(1, clusters.test_user_df, clusters.test_system_df, user_pred, sys_pred, clusters.test_dataset))\n",
    "print(\"Acc@3:\", get_all_accuracy_k(3, clusters.test_user_df, clusters.test_system_df, user_pred, sys_pred, clusters.test_dataset))\n",
    "print(\"Acc@5:\", get_all_accuracy_k(5, clusters.test_user_df, clusters.test_system_df, user_pred, sys_pred, clusters.test_dataset))\n",
    "print(\"Acc@10:\", get_all_accuracy_k(10, clusters.test_user_df, clusters.test_system_df, user_pred, sys_pred, clusters.test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2afc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
